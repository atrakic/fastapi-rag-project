services:
  client:
    build:
      context: ./client
      dockerfile: Dockerfile
    restart: always
    container_name: client
    environment:
      - API_SERVER=http://server:8000/api
    ports:
      - 3000:3000
    depends_on:
      - server
  server:
    build: ./server
    restart: always
    container_name: server
    env_file:
      - .env
    environment:
      - OLAMA_URL=http://ollama:11434
      - QDRANT_URL=http://qdrant:6333
      - OLAMA_MODEL=${OLAMA_MODEL:?"OLAMA_MODEL is required"}
    ports:
      - 8000:8000
    depends_on:
      - qdrant
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    tty: true
    env_file:
      - .env
    environment:
      - OLLAMA_ORIGINS="*"
      - OLLAMA_HOST=0.0.0.0
      - OLAMA_MODEL=${OLAMA_MODEL:?"OLAMA_MODEL is required"}
    entrypoint:
      - /bin/bash
      - -c
      - |
        /bin/ollama serve &
        # Record Process ID
        pid=$!
        # Wait for the server to start
        sleep 5
        # Pull the model
        /bin/ollama pull $${OLAMA_MODEL}
        # Wait for Ollama process to finish
        wait $$pid
    volumes:
      - ollama:/root/.ollama
  qdrant:
    image: qdrant/qdrant:latest
    restart: always
    container_name: qdrant
    ports:
      - 6333:6333 # Dashboard - localhost:6333/dashboard, REST API - localhost:6333
      - 6334:6334 # GRPC API - localhost:6334
    expose:
      - 6333
      - 6334
    configs:
      - source: qdrant_config
        target: /qdrant/config/production.yaml
    volumes:
      - $PWD/qdrant_data:/qdrant/storage

volumes:
  ollama:
  qdrant_data:

configs:
  qdrant_config:
    content: |
      log_level: INFO
